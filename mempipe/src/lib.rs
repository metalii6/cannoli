//! MemPipe! A high-performance, low-latency, high-bandwidth way of streaming
//! data from one core to another.
//!
//! This crate is effectively a collection of buffers which are allocated
//! in shared memory. The creator of the memory, [`SendPipe`], defines the
//! size of each chunk, and the number of chunks (number of buffers) to use
//! for sending to the other core.
//!
//! When the sender wants to send data, they request a buffer via
//! `alloc_buffer`. This gives them a write-only accessor [`ChunkWriter`] that
//! allows writing to this buffer. When the buffer is dropped it is tagged
//! with a sequence number and flagged as owned by the client.
//!
//! This design is for super low latency, allowing very small transfers while
//! still getting high memory-bandwidth. This is originally being designed as
//! a way to stream a log of control flow and register states from inside of
//! QEMU's JIT into another processes memory. The goal is to block QEMU as
//! little as possible, and thus latency and design of this structures memory
//! layout is critical.
//!
//! The way that we signal information between threads is on a separate cache
//! line from the raw backing data storage. This means that the producer may
//! be hammering on its data buffer, without causing cache coherency traffic
//! for the consumers that are polling metadata, waiting for data to be given
//! to them.

//#![no_std]
#![feature(maybe_uninit_uninit_array, array_from_fn, alloc_c_string)]
#![feature(scoped_threads, inline_const)]

extern crate alloc;

use core::mem::{MaybeUninit, size_of, size_of_val};
use core::cell::UnsafeCell;
use core::sync::atomic::{AtomicBool, AtomicUsize, AtomicU64, Ordering};
use alloc::vec::Vec;
use alloc::ffi::{CString, NulError};

/// A wrapper around the [`Error`] type
type Result<T> = core::result::Result<T, Error>;

/// Error types for this module
#[derive(Debug)]
pub enum Error {
    /// An error occurred while converting Rust bytes into a [`CString`]
    CString(NulError),

    /// Failed to open shared memory file
    ShmOpen,

    /// Failed to [`ftruncate`] shared memory when it was created
    SetMemorySize,

    /// Failed to [`mmap`] memory
    MapMemory,

    /// Attempted to connect to a pipe with a different configuration of
    /// chunk size or number of buffers
    PipeMismatch,

    /// The specified chunk size or number of buffers was invalid
    ///
    /// We expect non-zero number of buffers and size
    InvalidPipeConfiguration,
}

/// Wrapper around a chunk
#[repr(C, align(64))]
struct Chunk<const CHUNK_SIZE: usize>(
    [MaybeUninit<UnsafeCell<u8>>; CHUNK_SIZE]);

/// A memory pipe which uses `CHUNK_SIZE` byte chunks and `NUM_BUFFERS` for
/// transferring memory between processes.
///
/// This defines the actual shape of a memory pipe in memory, and this is what
/// is placed in shared memory at offset 0 of the allocated memory
#[repr(C)]
struct RawMemPipe<const CHUNK_SIZE: usize, const NUM_BUFFERS: usize> {
    /// The key generated by the creator of the [`SendPipe`], this is to
    /// provide some mechanism of preventing a developer from making a big
    /// mistake, connecting two mismatched pipes.
    ///
    /// This doesn't provide any security. It's really up to the permissions
    /// of the shared memory file itself. Sorry, don't have control over the
    /// Linux SHM APIs...
    ///
    /// This must be the first value in the structure
    key: u64,

    /// Size of a [`usize`] we expect, in bytes
    usize_size: u64,

    /// Size of this memory pipe. These are used to make sure both the sender
    /// and receiver are using the same constants
    chunk_size: u64,

    /// Number of buffers in this memory pipe. These are used to make sure both
    /// the sender and receiver are using the same constants
    num_buffers: u64,

    /// Boolean tracking whether or not each corresponding buffer is owned by
    /// the client. In our case, the client is the program who opened the
    /// existing shared memory buffer.
    client_owned: [AtomicBool; NUM_BUFFERS],

    /// Holds the length of a transferred buffer. This must be populated prior
    /// to `client_owned` being set to `true`, and must be ordered correctly
    /// on the processor
    client_len: [AtomicUsize; NUM_BUFFERS],

    /// The sequence number for a given buffer, must be set prior to
    /// `client_owned` and ordered correctly on the processor
    client_seq: [AtomicU64; NUM_BUFFERS],

    /// Current sequence number, incremented by one to get a sequential ID to
    /// tag outbound chunks with
    cur_seq: AtomicU64,

    /// Chunks
    chunks: [Chunk<CHUNK_SIZE>; NUM_BUFFERS],
}

/// The sending side of a pipe. To create one, call [`SendPipe::create`] with
/// a name which will be used to access this pipe.
pub struct SendPipe<'a, const CHUNK_SIZE: usize, const NUM_BUFFERS: usize> {
    /// Reference to the memory pipe
    mem_pipe: &'a RawMemPipe<CHUNK_SIZE, NUM_BUFFERS>,
}

impl<'a, const CHUNK_SIZE: usize, const NUM_BUFFERS: usize>
        SendPipe<'a, CHUNK_SIZE, NUM_BUFFERS> {
    /// Create a pipe with the given `name`. Returns the pipe and the `key`
    /// needed to create a [`RecvPipe`]
    ///
    /// This will delete the shared memory with `name`, and then create it
    /// exclusively. This will get us a unique inode atomically from the kernel
    /// for this given name.
    pub fn create(name: impl Into<Vec<u8>>) -> Result<(Self, u64)> {
        // Make sure settings are sane
        if NUM_BUFFERS == 0 || CHUNK_SIZE == 0 {
            return Err(Error::InvalidPipeConfiguration);
        }

        // Convert the Rust name into a `CString` for the current system
        let cs = CString::new(name).map_err(Error::CString)?;

        // Delete the shared memory before we create it to make sure we
        // exclusively create it
        unsafe { libc::shm_unlink(cs.as_ptr()); }

        // Create new shared memory
        let shm = unsafe {
            libc::shm_open(cs.as_ptr(),
                libc::O_CREAT | libc::O_EXCL | libc::O_RDWR,
                libc::S_IRUSR | libc::S_IWUSR)
        };
        if shm == -1 { return Err(Error::ShmOpen); }

        // Set the shared memory size
        if unsafe { libc::ftruncate(shm,
                size_of::<RawMemPipe<CHUNK_SIZE, NUM_BUFFERS>>() as i64) }
                    == -1 {
            return Err(Error::SetMemorySize);
        }

        // Map the shared memory
        let mapped = unsafe {
            libc::mmap(core::ptr::null_mut(),
                size_of::<RawMemPipe<CHUNK_SIZE, NUM_BUFFERS>>(),
                libc::PROT_READ | libc::PROT_WRITE, libc::MAP_SHARED,
                shm, 0) as *mut RawMemPipe<CHUNK_SIZE, NUM_BUFFERS>
        };
        if mapped as usize == libc::MAP_FAILED as usize {
            return Err(Error::MapMemory);
        }

        // Initialize the memory
        unsafe {
            mapped.write(RawMemPipe {
                key:          rand::random(),
                chunk_size:   CHUNK_SIZE  as u64,
                num_buffers:  NUM_BUFFERS as u64,
                usize_size:   size_of::<usize>() as u64,
                client_owned: [const { AtomicBool::new(false) }; NUM_BUFFERS],
                client_len:   [const { AtomicUsize::new(0)    }; NUM_BUFFERS],
                client_seq:   [const { AtomicU64::new(0)      }; NUM_BUFFERS],
                cur_seq:      AtomicU64::new(0),
                chunks: core::array::from_fn(|_| {
                    Chunk(MaybeUninit::uninit_array())
                }),
            });
        }

        // Memory is initialized, we can get a Rust reference now!
        let mem_pipe = unsafe { &*mapped };

        Ok((
            Self {
                mem_pipe,
            }, mem_pipe.key)
        )
    }

    /// Allocate a buffer from the pipe
    ///
    /// This will spin on the available buffers `mem_pipe.client_owned` until
    /// one is available. This intentionally does not raise to a OS-level wait,
    /// to optimize for latency and our use case.
    ///
    /// Only one buffer can be issued at a time. Rust gives this safety since
    /// we take `&mut self` here, thus, only one [`ChunkWriter`] can exist for
    /// any given [`SendPipe`] at a given time
    pub fn alloc_buffer(&mut self) -> ChunkWriter<CHUNK_SIZE, NUM_BUFFERS> {
        // Outer loop, look through buffers forever
        loop {
            // Check all buffers
            for ii in 0..NUM_BUFFERS {
                // See if this buffer is available for use (not client owned)
                if !self.mem_pipe.client_owned[ii].load(Ordering::Acquire) {
                    // Woo, we own this buffer, return it!
                    return ChunkWriter {
                        mem_pipe: self.mem_pipe,
                        idx:      ii,
                        written:  0,

                        // Construct a raw pointer to the first byte
                        bytes: UnsafeCell::raw_get(
                            self.mem_pipe.chunks[ii].0[0].as_ptr()
                        ),
                    };
                }
            }
        }
    }
}

/// A [`ChunkWriter`] is a wrapper around a [`Chunk`] which is currently. This
/// prevents all reading from the buffer, as buffers from `alloc_buffer` are
/// write-only.
///
/// When a chunk is dropped, it is sent over to the consumer immediately
pub struct ChunkWriter<'a, const CHUNK_SIZE: usize, const NUM_BUFFERS: usize> {
    /// Reference to the `MemPipe` we came from
    mem_pipe: &'a RawMemPipe<CHUNK_SIZE, NUM_BUFFERS>,

    /// Accessor to the raw underlying bytes, points to the first byte of a
    /// [`Chunk`]'s raw data
    bytes: *mut u8,

    /// Buffer index in the [`MemPipe`]
    idx: usize,

    /// Tracks the number of initialized bytes in the chunk
    written: usize,
}

impl<'a, const CHUNK_SIZE: usize, const NUM_BUFFERS: usize>
        ChunkWriter<'a, CHUNK_SIZE, NUM_BUFFERS> {
    /// Write data into the chunk and send it, consuming the `ChunkWriter` and
    /// returning the number of bytes sent
    pub fn send(mut self, data: impl AsRef<[u8]>) -> usize {
        // Compute the remaining size of the buffer
        let remain = CHUNK_SIZE - self.written;

        // Compute the number of bytes we can accept for this send
        let to_send = remain.min(data.as_ref().len());

        // Copy the data into the chunk
        unsafe {
            self.bytes.add(self.written)
                .copy_from_nonoverlapping(data.as_ref().as_ptr(), to_send);
        }

        // Update number of bytes written
        self.written += to_send;

        // Return number of copied and sent bytes
        to_send
    }

    /// Get a mutable reference to the backing memory
    pub fn get_raw(&mut self) -> *mut u8 {
        self.bytes
    }

    /// Send raw data, this takes the length sent, and assumes it is in-bounds
    /// and the bytes referred to have been initialized
    #[inline]
    pub unsafe fn send_raw(mut self, size: usize) {
        // Update the number of bytes written, we'll send it on drop!
        self.written = size;
    }
}

impl<'a, const CHUNK_SIZE: usize, const NUM_BUFFERS: usize> Drop for
        ChunkWriter<'a, CHUNK_SIZE, NUM_BUFFERS> {
    /// Drop a [`ChunkWriter`], this action sends ownership of the buffer to
    /// the client
    fn drop(&mut self) {
        // Send ownership of the buffer to the client

        // Populate the length
        self.mem_pipe.client_len[self.idx].store(self.written,
            Ordering::Relaxed);

        // Allocate a unique sequence ID for this buffer
        let seq_id = self.mem_pipe.cur_seq.fetch_add(1, Ordering::Relaxed);
        self.mem_pipe.client_seq[self.idx].store(seq_id, Ordering::Relaxed);

        // Flip ownership, using release semantics to make sure all writes have
        // become visible to the core we're sending to
        self.mem_pipe.client_owned[self.idx].store(true, Ordering::Release);
    }
}

/// The receiving side of a pipe, this will allow you to read sequenced data
/// as it was sent from a `SendPipe`
pub struct RecvPipe<'a, const CHUNK_SIZE: usize, const NUM_BUFFERS: usize> {
    /// Reference to the memory pipe
    mem_pipe: &'a RawMemPipe<CHUNK_SIZE, NUM_BUFFERS>,

    /// Current sequence index we're looking for
    seq: u64,
}

impl<'a, const CHUNK_SIZE: usize, const NUM_BUFFERS: usize>
        RecvPipe<'a, CHUNK_SIZE, NUM_BUFFERS> {
    /// Open a pipe with a given `name` and verify it matches the expected
    /// `key`
    pub fn open(name: impl Into<Vec<u8>>, key: u64) -> Result<Self> {
        // Make sure settings are sane
        if NUM_BUFFERS == 0 || CHUNK_SIZE == 0 {
            return Err(Error::InvalidPipeConfiguration);
        }

        // Convert the Rust name into a `CString` for the current system
        let cs = CString::new(name).map_err(Error::CString)?;

        // Open shared memory, only if it already exists
        let shm = unsafe { libc::shm_open(cs.as_ptr(), libc::O_RDWR, 0) };
        if shm == -1 { return Err(Error::ShmOpen); }

        // Read the configuration of the chunk
        unsafe {
            let mut tmp = [0u64; 4];

            // Read the header, which we can use to verify this pipe matches
            // what we expect
            if libc::read(shm, tmp.as_mut_ptr() as *mut _,
                    size_of_val(&tmp)) as usize != size_of_val(&tmp) {
                return Err(Error::PipeMismatch);
            }

            // Make sure everything matches as we expect
            if tmp[0] != key || tmp[1] != size_of::<usize>() as u64 ||
                    tmp[2] != CHUNK_SIZE  as u64 ||
                    tmp[3] != NUM_BUFFERS as u64 {
            }
        }

        // Map the shared memory
        let mapped = unsafe {
            libc::mmap(core::ptr::null_mut(),
                size_of::<RawMemPipe<CHUNK_SIZE, NUM_BUFFERS>>(),
                libc::PROT_READ | libc::PROT_WRITE, libc::MAP_SHARED,
                shm, 0) as *mut RawMemPipe<CHUNK_SIZE, NUM_BUFFERS>
        };
        if mapped as usize == libc::MAP_FAILED as usize {
            return Err(Error::MapMemory);
        }

        // Return a reference to the memory pipe
        Ok(RecvPipe {
            mem_pipe: unsafe { &*mapped },
            seq:      0,
        })
    }

    /// Wait to recieve the next message, then invoke the closure with a slice
    /// to the data which was received
    pub fn recv(&mut self, mut func: impl FnMut(&[u8])) {
        // Wait forever
        loop {
            // Look for a filled in buffer
            for ii in 0..NUM_BUFFERS {
                // If it's not client owned, skip it
                if !self.mem_pipe.client_owned[ii].load(Ordering::Acquire) {
                    continue;
                }

                // It's client owned, make sure it's the sequence we expect
                if self.seq != self.mem_pipe
                        .client_seq[ii].load(Ordering::Relaxed) {
                    continue;
                }

                // Got the sequence we wanted, get the length
                let length =
                    self.mem_pipe.client_len[ii].load(Ordering::Relaxed);

                // Get a slice to the data
                let data = unsafe {
                    core::slice::from_raw_parts(
                        UnsafeCell::raw_get(
                            self.mem_pipe.chunks[ii].0[0].as_ptr()),
                        length)
                };

                // Invoke the callback, giving the user access to the data
                // temporarily before we give it back to the sender
                func(data);

                // Move ownership back to the sender
                self.mem_pipe.client_owned[ii].store(false, Ordering::Release);

                // Update sequence we expect
                self.seq = self.seq.wrapping_add(1);

                // All done!
                return;
            }
        }
    }
}

#[test]
fn test() {
    const NUM_CHUNKS: usize = 1024 * 1024;
    const CHUNK_SIZE: usize = 128 * 1024;

    std::thread::scope(|s| {
        s.spawn(|| {
            // Create the pipe
            let (mut pipe, key) =
                SendPipe::<CHUNK_SIZE, 4>::create("moose").unwrap();

            // Create accessor pipe
            s.spawn(move || {
                let mut pipe =
                    RecvPipe::<CHUNK_SIZE, 4>::open("moose", key).unwrap();

                let mut rxed = 0;
                let it = std::time::Instant::now();
                for _ in 0..NUM_CHUNKS {
                    pipe.recv(|result| {
                        rxed += result.len();
                    });
                }
                let elapsed = it.elapsed().as_secs_f64();

                println!("{:12.8} GiB/sec",
                    rxed as f64 / 1024. / 1024. / 1024. / elapsed);
            });

            // Request a buffer
            for _ in 0..NUM_CHUNKS {
                const TMP: [u8; CHUNK_SIZE] = [0; CHUNK_SIZE];
                let buf = pipe.alloc_buffer();
                buf.send(TMP);
            }
        });
    });
}

